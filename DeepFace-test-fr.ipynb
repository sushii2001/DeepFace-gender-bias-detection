{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepface Face Recognition Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface\n",
    "from deepface import DeepFace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd                 \n",
    "import regex as re\n",
    "\n",
    "# directory cleaning\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# change plot output to white\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# result_df = pd.read_csv('./result/result_debface.csv')\n",
    "# benchmark_df = pd.read_csv('./data/LFW-csv/pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a DATASET from data folder:\n",
    "# LFW, LFW-original\n",
    "DATASET = \"LFW\"\n",
    "\n",
    "# select a dataset from additional-data folder:\n",
    "# tzuyu, kpop\n",
    "DATASET_TEST = \"tzuyu\"\n",
    "\n",
    "# select a model to run:\n",
    "# models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
    "MODEL = \"Facenet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset directory and test instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Test additional data directory:\n",
    "# dir_path = f\"./additional-data/{DATASET_TEST}\"\n",
    "\n",
    "# Test dataset directory:\n",
    "dir_path = f\"./data/{DATASET}\"\n",
    "\n",
    "# list all files in the directory\n",
    "all_dir_path = os.listdir(dir_path)\n",
    "\n",
    "# Removes previously stored representations_FACE.pkl, as adding new instances requires to re-test the model\n",
    "## For LFW dataset\n",
    "for item in all_dir_path:\n",
    "    item_path = f\"./data/{DATASET}/{item}\"\n",
    "    sub_files = os.listdir(item_path) \n",
    "    for sub_item in sub_files:\n",
    "        if sub_item.endswith(\".pkl\"):\n",
    "            os.remove(os.path.join(item_path, sub_item))\n",
    "\n",
    "## For random data dataset\n",
    "# for item in all_dir_path:\n",
    "#     if item.endswith(\".pkl\"):\n",
    "#         os.remove(os.path.join(dir_path, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to test Deepface Face recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find accuracy of specific person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepface_get_accuracy(model_used, dir_path):\n",
    "    # Recoginize all images in the dataset and verify them\n",
    "    # calculate accuracy by dividing the number true image by the total number of images recognized\n",
    "\n",
    "    # store the results of each verification:\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    total_images = os.listdir(dir_path)\n",
    "    num_images = len(total_images)\n",
    "\n",
    "    # Skip if folder only contains 1 image\n",
    "    if num_images < 1:\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            # select the first image as image to recognise \n",
    "            image_truth = f\"{dir_path}/{total_images[0]}\"\n",
    "            \n",
    "            # set enforce_detection to False for full body images  \n",
    "            df = pd.DataFrame(DeepFace.find(img_path = image_truth, \n",
    "                                            db_path = dir_path, \n",
    "                                            model_name = model_used, \n",
    "                                            enforce_detection=False))\n",
    "            \n",
    "            # declare truth images, noise, image_name\n",
    "            truth_images = []\n",
    "            noise = []\n",
    "            match = re.search(f\"_\\d.*\\.jpg\", str(total_images[0]))\n",
    "            NAME = total_images[0].replace(match.group(0), \"\")\n",
    "\n",
    "            # find total ground truth images\n",
    "            for image in total_images[1:]:\n",
    "                if re.search(f\"{NAME}_\\d.*\\.jpg\", str(image)):                                          \n",
    "                    truth_images.append(image) \n",
    "                else:\n",
    "                    noise.append(image)\n",
    "            \n",
    "            # loop through the images that were recognised \n",
    "            for image in df['identity'][1:]:\n",
    "                if re.search(f\".*\\/{NAME}_\\d.*\\.jpg\", str(image)):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "\n",
    "            tn = len(noise) - fp\n",
    "            fn = len(truth_images) - tp\n",
    "\n",
    "            # calculate confusion matrix accuracy\n",
    "            cm_acc = round( (tp + tn)/(tp + tn + fp + fn), 2) * 100\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return {\"Model\": model_used, \"Dataset\": DATASET, \"CM_Accuracy\": cm_acc, \"Total Images\": num_images-1}, \\\n",
    "                {\"tp\": tp, \"tn\":tn, \"fp\":fp, \"fn\":fn, \"truth\":truth_images, \"noise\":noise}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find accuracy for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepface_dataset_fr(model_used, dir_path):\n",
    "    avg_truth_pos = 0\n",
    "    avg_truth_neg = 0\n",
    "    avg_false_pos = 0\n",
    "    avg_false_neg = 0\n",
    "    total_imgs = 0\n",
    "    \n",
    "    # load the people from the dataset\n",
    "    people_images = os.listdir(dir_path)\n",
    "\n",
    "    # loop through each people and execute the deepface face recognition test\n",
    "    for people in people_images:\n",
    "        people_img_path = f\"{dir_path}/{people}\"\n",
    "        \n",
    "        deepface_res, cm_attr = deepface_get_accuracy(model_used, people_img_path)\n",
    "\n",
    "        if deepface_res and cm_attr == None:\n",
    "            pass\n",
    "        else:\n",
    "            avg_truth_pos += cm_attr[\"tp\"]\n",
    "            avg_truth_neg += cm_attr[\"tn\"]\n",
    "            avg_false_pos += cm_attr[\"fp\"]\n",
    "            avg_false_neg += cm_attr[\"fn\"]\n",
    "            total_imgs += deepface_res[\"Total Images\"]\n",
    "\n",
    "    # calculate confusion matrix:\n",
    "    # accuracy:\n",
    "    cm_acc = round((avg_truth_pos + avg_truth_neg) / (avg_truth_pos + avg_truth_neg + avg_false_pos + avg_false_neg), 2) * 100\n",
    "    # precision:\n",
    "    cm_pre = round( (avg_truth_pos) / (avg_truth_pos + avg_false_pos), 2) * 100\n",
    "    # recall: \n",
    "    cm_rec = round( (avg_truth_pos) / (avg_truth_pos + avg_false_neg), 2) * 100\n",
    "\n",
    "    return {\"Model\": model_used, \"Dataset\": DATASET, \"CM_Accuracy\": cm_acc, \"Precision\":cm_pre, \"Recall\":cm_rec, \"Total Images\": total_imgs},\\\n",
    "            {\"TP\": avg_truth_pos, \"TN\":avg_truth_neg, \"FP\":avg_false_pos, \"FN\":avg_false_neg}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of Deepface testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Representations stored in  ./additional-data/tzuyu / representations_facenet.pkl  file. Please delete this file when you add new identities in your database.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "find function lasts  0.8691086769104004  seconds\n"
     ]
    }
   ],
   "source": [
    "# Run Deepface face recognition testing:\n",
    "deepface_res, cm_attr = deepface_get_accuracy(MODEL, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  ./data/LFW/Aaron_Eckhart  folder were previously stored in  representations_facenet.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  1  representations found in  representations_facenet.pkl\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "find function lasts  0.11499834060668945  seconds\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Representations stored in  ./data/LFW/Aaron_Guiel / representations_facenet.pkl  file. Please delete this file when you add new identities in your database.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "find function lasts  0.1995527744293213  seconds\n",
      "division by zero\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'cm_acc' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\EzLaser\\Desktop\\MDS4\\project\\DeepFace-gender-bias-detection\\DeepFace-test-fr.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run Deepface face recognition on entire dataset:\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m deepface_res_dataset, cm_attr \u001b[39m=\u001b[39m deepface_dataset_fr(MODEL, dir_path)\n",
      "\u001b[1;32mc:\\Users\\EzLaser\\Desktop\\MDS4\\project\\DeepFace-gender-bias-detection\\DeepFace-test-fr.ipynb Cell 17\u001b[0m in \u001b[0;36mdeepface_dataset_fr\u001b[1;34m(model_used, dir_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m people \u001b[39min\u001b[39;00m people_images:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     people_img_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdir_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mpeople\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     deepface_res, cm_attr \u001b[39m=\u001b[39m deepface_get_accuracy(model_used, people_img_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m deepface_res \u001b[39mand\u001b[39;00m cm_attr \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\EzLaser\\Desktop\\MDS4\\project\\DeepFace-gender-bias-detection\\DeepFace-test-fr.ipynb Cell 17\u001b[0m in \u001b[0;36mdeepface_get_accuracy\u001b[1;34m(model_used, dir_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mprint\u001b[39m(e)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m\"\u001b[39m: model_used, \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m: DATASET, \u001b[39m\"\u001b[39m\u001b[39mCM_Accuracy\u001b[39m\u001b[39m\"\u001b[39m: cm_acc, \u001b[39m\"\u001b[39m\u001b[39mTotal Images\u001b[39m\u001b[39m\"\u001b[39m: num_images\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m}, \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EzLaser/Desktop/MDS4/project/DeepFace-gender-bias-detection/DeepFace-test-fr.ipynb#X34sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m\"\u001b[39m: tp, \u001b[39m\"\u001b[39m\u001b[39mtn\u001b[39m\u001b[39m\"\u001b[39m:tn, \u001b[39m\"\u001b[39m\u001b[39mfp\u001b[39m\u001b[39m\"\u001b[39m:fp, \u001b[39m\"\u001b[39m\u001b[39mfn\u001b[39m\u001b[39m\"\u001b[39m:fn, \u001b[39m\"\u001b[39m\u001b[39mtruth\u001b[39m\u001b[39m\"\u001b[39m:truth_images, \u001b[39m\"\u001b[39m\u001b[39mnoise\u001b[39m\u001b[39m\"\u001b[39m:noise}\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'cm_acc' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Run Deepface face recognition on entire dataset:\n",
    "deepface_res_dataset, cm_attr = deepface_dataset_fr(MODEL, dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from Deepface testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Facenet', 'Dataset': 'LFW', 'CM_Accuracy': 75.0, 'Total Images': 4}\n",
      "{'tp': 3, 'tn': 0, 'fp': 0, 'fn': 1, 'truth': ['tzuyu_0002.jpg', 'tzuyu_0003.jpg', 'tzuyu_0004.jpg', 'tzuyu_0008_wear.jpg'], 'noise': []}\n"
     ]
    }
   ],
   "source": [
    "# print(f'Accuracy of {model_used} is {acc}% out of {len(result)} images')\n",
    "print(deepface_res)\n",
    "print(cm_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing results to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_new = pd.DataFrame([deepface_res])\n",
    "\n",
    "frames = [result_df, result_df_new]\n",
    "result_df = pd.concat(frames)\n",
    "\n",
    "result_df = result_df.reset_index()\n",
    "result_df.drop(columns=['index'], inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to csv file\n",
    "result_df.to_csv(\"./result/result_debface_fr.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DeepfaceVE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81a04c2f423b520ddc272671c1bc5381e7218e0e6f14c84e06e4ed043ef6ecc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
