{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import metrics\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat = scipy.io.loadmat('./data/IMDB/wiki_crop/wiki.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sami Jauhojärvi]</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>[48/10000548_1925-04-04_1964.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Dettmar Cramer]</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Marc Okrand]</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>705061</td>\n",
       "      <td>1961</td>\n",
       "      <td>[65/10001965_1930-05-23_1961.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Aleksandar Matanović]</td>\n",
       "      <td>[[1, 1, 634, 440]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Diana Damrau]</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                          full_path  gender  \\\n",
       "0  723671         2009  [17/10000217_1981-05-05_2009.jpg]     1.0   \n",
       "1  703186         1964  [48/10000548_1925-04-04_1964.jpg]     1.0   \n",
       "2  711677         2008    [12/100012_1948-07-03_2008.jpg]     1.0   \n",
       "3  705061         1961  [65/10001965_1930-05-23_1961.jpg]     1.0   \n",
       "4  720044         2012  [16/10002116_1971-05-31_2012.jpg]     0.0   \n",
       "\n",
       "                     name                                      face_location  \\\n",
       "0       [Sami Jauhojärvi]  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1        [Dettmar Cramer]  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2           [Marc Okrand]      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "3  [Aleksandar Matanović]                                 [[1, 1, 634, 440]]   \n",
       "4          [Diana Damrau]  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "\n",
       "   face_score  second_face_score  \n",
       "0    4.300962                NaN  \n",
       "1    2.645639           1.949248  \n",
       "2    4.329329                NaN  \n",
       "3        -inf                NaN  \n",
       "4    3.408442                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = mat['wiki'][0][0][0].shape[1]\n",
    " \n",
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\"]\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(index = range(0,instances), columns = columns)\n",
    " \n",
    "for i in mat:\n",
    "    if i == \"wiki\":\n",
    "        current_array = mat[i][0][0]\n",
    "        for j in range(len(current_array)):\n",
    "            df[columns[j]] = pd.DataFrame(current_array[j][0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    12622\n",
       "1.0    47063\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of output classes:  2\n"
     ]
    }
   ],
   "source": [
    "classes = 2 #man woman\n",
    "print(\"number of output classes: \",classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datenum_to_datetime(datenum):\n",
    "    days = datenum % 1\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    exact_date = datetime.fromordinal(int(datenum)) \\\n",
    "        + timedelta(days=int(days)) + timedelta(hours=int(hours)) \\\n",
    "        + timedelta(minutes=int(minutes)) + timedelta(seconds=round(seconds)) \\\n",
    "        - timedelta(days=366)\n",
    "    \n",
    "    return exact_date.year\n",
    " \n",
    "df['date_of_birth'] = df['dob'].apply(datenum_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['photo_taken'] - df['date_of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pictures does not include face\n",
    "df = df[df['face_score'] != -np.inf]\n",
    " \n",
    "#some pictures include more than one face, remove them\n",
    "df = df[df['second_face_score'].isna()]\n",
    " \n",
    "#check threshold\n",
    "df = df[df['face_score'] >= 3]\n",
    " \n",
    "#some records do not have a gender information\n",
    "df = df[~df['gender'].isna()]\n",
    " \n",
    "df = df.drop(columns = ['name','face_score','second_face_score','date_of_birth','face_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n",
    "df = df[df['age'] <= 100]\n",
    " \n",
    "#some guys seem to be unborn in the data set\n",
    "df = df[df['age'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    " \n",
    "def getImagePixels(image_path):\n",
    "    img = load_img(\"./data/IMDB/wiki_crop/%s\" % image_path[0], grayscale=False, target_size=target_size)\n",
    "    x = img_to_array(img).reshape(1, -1)[0]\n",
    "    #x = preprocess_input(x)\n",
    "    return x\n",
    " \n",
    "df['pixels'] = df['full_path'].apply(getImagePixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['gender'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    " \n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "    \n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22138, 224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features /= 255 #normalize in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.72 GiB for an array with shape (6642, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34920\\2181255786.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2441\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m     return list(\n\u001b[0m\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[0;32m   2445\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2443\u001b[0m     return list(\n\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[1;32m-> 2445\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2446\u001b[0m         )\n\u001b[0;32m   2447\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.72 GiB for an array with shape (6642, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Face model\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[7,7,512,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11764\\246804908.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2622\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\DebFaceVE\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._generator.uniform(\n\u001b[0;32m   1919\u001b[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001b[1;32m-> 1920\u001b[1;33m     return tf.random.uniform(\n\u001b[0m\u001b[0;32m   1921\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(2622, (1, 1)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-trained weights of vgg-face model.\n",
    "#you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "#related blog post: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze all layers of VGG-Face except last 7 one\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(classes, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "gender_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check trainable layers\n",
    "if False:\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "    \n",
    "    print(\"------------------------\")\n",
    "    for layer in age_model.layers:\n",
    "        print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "gender_model.compile(loss='categorical_crossentropy'\n",
    "                  , optimizer=keras.optimizers.Adam()\n",
    "                  #, optimizer = sgd\n",
    "                  , metrics=['accuracy']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='classification_gender_model.hdf5'\n",
    "    , monitor = \"val_loss\"\n",
    "    , verbose=1\n",
    "    , save_best_only=True\n",
    "    , mode = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enableFit = False\n",
    "\n",
    "if enableFit:\n",
    "    epochs = 250\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print(\"epoch \",i)\n",
    "        \n",
    "        ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    "        \n",
    "        score = gender_model.fit(\n",
    "            train_x[ix_train], train_y[ix_train]\n",
    "            , epochs=1\n",
    "            , validation_data=(test_x, test_y)\n",
    "            , callbacks=[checkpointer]\n",
    "        )\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "        from keras.models import load_model\n",
    "        gender_model = load_model(\"classification_gender_model.hdf5\")\n",
    "        \n",
    "        gender_model.save_weights('gender_model_weights.h5')\n",
    "        \n",
    "else:\n",
    "    #pre-trained weights for gender prediction: https://drive.google.com/file/d/1wUXRVlbsni2FN9-jkS_f4UTUrm1bRLyk/view?usp=sharing\n",
    "    gender_model.load_weights(\"gender_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_change = []; loss_change = []\n",
    "for i in range(0, len(scores)):\n",
    "    val_loss_change.append(scores[i].history['val_loss'])\n",
    "    loss_change.append(scores[i].history['loss'])\n",
    "\n",
    "plt.plot(val_loss_change, label='val_loss')\n",
    "plt.plot(loss_change, label='train_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and accuracy on validation set\n",
    "gender_model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gender_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_list = []; actual_list = []\n",
    "\n",
    "for i in predictions:\n",
    "    pred_list.append(np.argmax(i))\n",
    "\n",
    "for i in test_y: \n",
    "    actual_list.append(np.argmax(i))\n",
    "\n",
    "confusion_matrix(actual_list, pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(filepath):\n",
    "    test_img = image.load_img(filepath, target_size=(224, 224))\n",
    "    test_img = image.img_to_array(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis = 0)\n",
    "    test_img /= 255\n",
    "    return test_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DeepfaceVE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81a04c2f423b520ddc272671c1bc5381e7218e0e6f14c84e06e4ed043ef6ecc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
